{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15c532c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MeCab\n",
    "import mojimoji\n",
    "import re\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c502f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/livedoor-homme'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518e157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../livedoornews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bd81c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://news.livedoor.com/article/detail/5978741/</td>\n",
       "      <td>2011-10-30T10:15:00+0900</td>\n",
       "      <td>【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か</td>\n",
       "      <td>2005年11月から翌2006年7月まで読売新聞にて連載された、直木賞作家・角田光代による初...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6322901/</td>\n",
       "      <td>2012-02-29T11:45:00+0900</td>\n",
       "      <td>藤原竜也、中学生とともにロケット打ち上げに成功</td>\n",
       "      <td>「アンテナを張りながら生活をしていけばいい」\\n2月28日、映画『おかえり、はやぶさ』（3月...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6176324/</td>\n",
       "      <td>2012-01-09T14:00:00+0900</td>\n",
       "      <td>『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席</td>\n",
       "      <td>3月2日より全国ロードショーとなる、スティーブン・スピルバーグの待望の監督最新作『戦火の馬』...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6573929/</td>\n",
       "      <td>2012-05-19T12:00:00+0900</td>\n",
       "      <td>香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」</td>\n",
       "      <td>女優の香里奈が18日、都内で行われた映画『ガール』（5月26日公開）の女子高生限定試写会にサ...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://news.livedoor.com/article/detail/5914880/</td>\n",
       "      <td>2011-10-05T19:11:00+0900</td>\n",
       "      <td>ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」</td>\n",
       "      <td>5日、東京・千代田区の内幸町ホールにて、映画『キャプテン・アメリカ/ザ・ファースト・アベンジ...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url                  datetime  \\\n",
       "0  http://news.livedoor.com/article/detail/5978741/  2011-10-30T10:15:00+0900   \n",
       "1  http://news.livedoor.com/article/detail/6322901/  2012-02-29T11:45:00+0900   \n",
       "2  http://news.livedoor.com/article/detail/6176324/  2012-01-09T14:00:00+0900   \n",
       "3  http://news.livedoor.com/article/detail/6573929/  2012-05-19T12:00:00+0900   \n",
       "4  http://news.livedoor.com/article/detail/5914880/  2011-10-05T19:11:00+0900   \n",
       "\n",
       "                                 title  \\\n",
       "0  【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か   \n",
       "1              藤原竜也、中学生とともにロケット打ち上げに成功   \n",
       "2    『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席   \n",
       "3     香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」   \n",
       "4     ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」   \n",
       "\n",
       "                                                body        media  \n",
       "0  2005年11月から翌2006年7月まで読売新聞にて連載された、直木賞作家・角田光代による初...  movie-enter  \n",
       "1  「アンテナを張りながら生活をしていけばいい」\\n2月28日、映画『おかえり、はやぶさ』（3月...  movie-enter  \n",
       "2  3月2日より全国ロードショーとなる、スティーブン・スピルバーグの待望の監督最新作『戦火の馬』...  movie-enter  \n",
       "3  女優の香里奈が18日、都内で行われた映画『ガール』（5月26日公開）の女子高生限定試写会にサ...  movie-enter  \n",
       "4  5日、東京・千代田区の内幸町ホールにて、映画『キャプテン・アメリカ/ザ・ファースト・アベンジ...  movie-enter  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd37f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/arata-honda/items/6409e387027c31365741\n",
    "#colabとlocalは後で設定で使い分けられるようにする\n",
    "class WordDividor:\n",
    "    INDEX_CATEGORY = 0\n",
    "    #TARGET_CATEGORY = ['名詞', '動詞', '形容詞']\n",
    "\n",
    "    def __init__(self, dictionary=\"mecabrc\"):\n",
    "        self.dictionary = dictionary\n",
    "        \n",
    "        if dictionary == 'mecabrc':\n",
    "            self.tagger = MeCab.Tagger()\n",
    "        elif dictionary == 'neologd':\n",
    "            self.tagger = MeCab.Tagger(f\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "\n",
    "    def extract_words_for_google_colab(self, text):\n",
    "        if not text:\n",
    "            return []\n",
    "\n",
    "        # テキストの余分なデータの削除(ex : httpなど)\n",
    "        text = re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "        text = re.sub(r'[!-~]', \"\", text)  # 半角記号,数字,英字\n",
    "        text = re.sub(r'[︰-＠]', \"\", text)  # 全角記号\n",
    "        text = re.sub('\\n', \" \", text)  # 改行文字\n",
    "\n",
    "        self.tagger.parse(\"\")\n",
    "        node = self.tagger.parseToNode(text)\n",
    "        words = []\n",
    "        while node:\n",
    "            if node.feature.split(\",\")[0] == u\"名詞\":\n",
    "                #print(node.feature)\n",
    "                word = node.feature.split(',')[6]\n",
    "                #print(word)\n",
    "                words.append(word)\n",
    "            elif node.feature.split(\",\")[0] == u\"形容詞\":\n",
    "                #print(node.feature)\n",
    "                word = node.feature.split(',')[6]\n",
    "                #print(word)\n",
    "                words.append(word)\n",
    "            elif node.feature.split(\",\")[0] == u\"動詞\":\n",
    "                #print(node.feature)\n",
    "                word = node.feature.split(',')[6]\n",
    "                #print(word)\n",
    "                words.append(word)\n",
    "            node = node.next\n",
    "        return words\n",
    "    \n",
    "    def extract_words_for_local(self, text):\n",
    "        if not text:\n",
    "            return []\n",
    "\n",
    "        # テキストの余分なデータの削除(ex : httpなど)\n",
    "        text = re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
    "        text = re.sub(r'[!-~]', \"\", text)  # 半角記号,数字,英字\n",
    "        text = re.sub(r'[︰-＠]', \"\", text)  # 全角記号\n",
    "        text = re.sub('\\n', \" \", text)  # 改行文字\n",
    "\n",
    "        self.tagger.parse(\"\")\n",
    "        node = self.tagger.parseToNode(text)\n",
    "        words = []\n",
    "        while node:\n",
    "            if node.feature.split(\",\")[0] == u\"名詞\":\n",
    "                #print(node.feature)\n",
    "                word = node.feature.split(',')[5]\n",
    "                #print(word)\n",
    "                words.append(word)\n",
    "            elif node.feature.split(\",\")[0] == u\"形容詞\":\n",
    "                #print(node.feature)\n",
    "                word = node.feature.split(',')[5]\n",
    "                #print(word)\n",
    "                words.append(word)\n",
    "            elif node.feature.split(\",\")[0] == u\"動詞\":\n",
    "                #print(node.feature)\n",
    "                word = node.feature.split(',')[5]\n",
    "                #print(word)\n",
    "                words.append(word)\n",
    "            node = node.next\n",
    "        return words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f22ba",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "321d3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全角を半角に統一\n",
    "df['text'] = df['body'].apply(lambda text: mojimoji.zen_to_han(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe1e5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#形態素解析\n",
    "wd = WordDividor('neologd')\n",
    "#df['text'] = df['text'].apply(lambda text: wd.extract_words_for_local(text))\n",
    "df['text'] = df['text'].apply(lambda text: wd.extract_words_for_google_colab(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d65d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda text: ' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d3671b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [text for text in df['text'].tolist()]\n",
    "words = (' '.join(text_list)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c106f0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45442"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先行研究の語彙数は34772(文章中に5回以上出現しない単語は削除した場合)\n",
    "len(set(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b0e04",
   "metadata": {},
   "source": [
    "## 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7fe2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../output/preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8103e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
